Este capítulo apresenta, inicialmente os diferentes tipos de escalonadores, citando as várias áreas em que a atividade de escalonamento ocorre, seguido da definição do problema de escalonamento que este trabalho busca resolver. Em sequência é discorrido sobre trabalhos relacionados para então apresentar o algoritmo de escalonamento proposto.

\section{Tipos de escalonadores}
O escalonamento é um problema clássico da computação. Que surgiu junto com os sistemas operacionais multitarefas. Sua complexidade é considerada NP-difícil, porém isso não impediu a evolução dos sistemas operacionais, cujos escalonadores são desenvolvidos com objetivos e metodologias diferentes para alcançarem esses objetivos. De qualquer forma um problema que todos os sistemas operacionais multitarefa buscam resolver é o \textit{starvation}, que é quando um processo/\textit{thread} permanece em execução por muito tempo, impedindo que outros sejam executados.

Escalonadores podem ser categorizados de várias formas, com base nas funcionalidades que possui, eis alguns exemplos:

\begin{itemize}
	\item \textbf{O que é escalonado}: Podem ser:
	\begin{itemize}
		\item processos, \textit{threads} para serem executados;
		\item jobs para serem excecutados na nuvem;
		\item páginas da memória \acrfull{RAM} para \textit{swapping};
		\item pacotes para serem transmitidos pela rede;
		\item requisições de leitura/escrita em memória secundária.
	\end{itemize}
	\item \textbf{Suporte para preempção}: Se permite interrupção de uma tarefa em execução para atender outras;
	\item \textbf{Suporte para prioridade}: Se permite que priorização entre as tarefas que serão escalonadas;
	\item \textbf{Suporte para para tempo-real}: Se permite que requerem execução constante tenham esse requisito atendido.
\end{itemize}


O problema do escalonamento é o método pelo qual trabalho, definido por algum conjunto de características(como duração e requisitos), é atribuído à recursos que capazes de completá-lo. Por mais que exista a dificuldade teórica\cite{ULLMAN1975384}, isso não impediu a evolução dos Sistemas Operacionais, os quais foram capazes de fazer escalonamento de vários processos mesmo na época de \acrfull{CPU}s tinham apenas um núcleo. Popularizando dessa forma os computadores pessoais na década de 80.
Atualmente, as \acrshort{CPU}s possuem vários núcleos, e são capazes de ter mais de um contexto carregado por núcleo, vide Ryzen™ Threadripper™\cite{Ryzen}. O que faz com que seja necessário que o processo de escalonamento leve em consideração como o mesmo será distribuído(ou não) entre os núcleos.

A atividade de escalonamento pode ser otimizada para vários objetivos, entre os quais podemos citar:
\begin{itemize}
	\item Maximinizar quantidade de trabalho realizada por unidade de tempo;
	\item Minimizar tempo no qual trabalhos ficam esperando para serem executados;
	\item Minimizar tempo entre um conjunto de trabalhos estarem prontos para serem executados até o fim da execução do conjunto(latência ou tempo de resposta);
	\item Distribuir de forma justa o tempo que cada um dos trabalhos terão de uso de um recurso escasso.
\end{itemize}

Esses objetivos são, às vezes, contraditórios. Na prática prioriza-se um conjunto de métricas como base para otimização. Por exemplo o GNU/Linux utiliza o \acrfull{CFS}, que se baseia no algoritmo \textit{Fair queuing}. Como o nome já diz, o foco desse escalonador está em ser justo. Internamente utiliza-se uma árvore rubro-negra indexados pelo tempo gasto no processador. Para ser justo, o tempo máximo de cada processo fica em execução interrupta é o quociente do tempo que o processo ficou aguardando para ser executado pelo número total de processos.

\section{Escalonamento em Nuvens Computacionais}

Este trabalho focará no escalonamento em federações de nuvens computacionais. O qual recentemente presenciou a ascensão do uso de unidades de processamento gráfico(\acrfull{GPU}) para processamento de propósito geral (\acrfull{GPGPU}\cite{Dimitrov:2009:USA:1513895.1513907}\cite{Yang:2010:GCM:1809028.1806606}. Nesse contexto, o problema do escalonamento pode ser formalmente definido da seguinte forma:\\
Dado:
\begin{itemize}
	\item Conjunto $T$ de tarefas;
	\item Conjunto $M$ de máquinas virtuais;
	\item Conjunto $C, |C| = |M|$ de CPUs das máquinas virtuais;
	\item Conjunto $G,  |G| \le |M|$ de GPUs das máquinas virtuais;
	\item Função $F: T \times (C \cup G) \to \mathbb{R}$, o qual estima o tempo de execução da tarefa $T_{i}$ no recurso designado.
\end{itemize}
Encontrar uma função injetora $A: T \to C \cup G$, que minimize $\sum_{t \in T} F(t, A(t) )$.\\

Por mais que o problema do escalonamento seja um clássico na área da Ciência da Computação, são poucos que lidam com escalonamento em nuvens computacionais, e ainda menos que lidam com nuvens compostas por arquiteturas heterogêneas. 

Gouasmi\cite{MapReduce_sched_8034997} apresenta um algoritmo de \textit{MapReduce}\cite{Dean:2008:MSD:1327452.1327492} para escalonamento em nuvens federadas que foca em priorizar a execução de \textit{jobs} em nuvens/máquinas virtuais que já contém os dados necessários para a execução, com o objetivo de evitar transferências desnecessárias na rede. O algoritmo proposto é completamente distribuído e melhor que o \textit{MapReduce} anteriormente utilizado, porém nada é dito sobre escalonamento para máquinas com arquiteturas heterogêneas.

Nguyen\cite{7791859} propõe um sistema de intermediação para federações de nuvens horizontais, com foco em busca da melhor nuvem para auxiliar sobrecarga de serviços para execução. Levando em consideração que provedores de nuvens diferentes podem ter sua infraestrutura customizada com o objetivo de atender diferentes perfis de usuários que mais usam seus serviços, o algoritmo proposto leva em consideração tais características invididuais de cada provedor. Novamente, nada é dito sobre nuvens compostas por equipamentos com arquiteturas heterogêneas.

Jennings\cite{Jennings:2015:RMC:2793474.2793493} documenta  várias metodologias, utilizadas em diferentes contextos que o escalonamento ocorre em ambientes de nuvens computacionais, revelando detalhadamente muitos dos problemas enfrentados durante a concepção. Entretanto nada é citado sobre federações de nuvens e os problemas de escalonamento enfrentados internamente num provedor de nuvem diferem dos enfrentados em ambientes de federação.

Kumrai\cite{7467407} trata do escalonamento de tarefas do ponto de vista do intermediador, utilizando \textit{particle swarm optimization}, que busca imitar um bando de pássaros. Cada elemento da população representa uma possível solução, que ao longo de interações tendem a encontrar a o melhor resultado, baseado numa função que avalia quão bom cada elemento da população está. Também analisa uma variação multiobjetivo do \textit{particle swarm optimization}, buscando solução boas tanto para o provedor de nuvem quanto para quem solicita os serviços. O problema do escalonamento apreciado nesse artigo possui contexto similar ao que será enfrentado nesta monografia, entretanto, não é tratado problema criado pelo uso de máquinas compostas por arquiteturas heterogêneas.

Mostageran\cite{7224588} documenta sobre intermediadores, conhecidos como \textit{bokers}. Com foco em sua evolução para atender a níveis de qualidade de serviços propostos em \acrshort{SLA}s. Apresentando definições úteis para termos utilizados na área, como \textit{inter-cloud}, federação de nuvens e \textit{cloud broker}. É importante diferenciar escalonador de intermediário: o intermediário mantém registro de entidades interessadas em um serviço e provedores desse serviço, incluindo busca de provedores e monitoramento das conexões feitas entre os interessados e os provedores; o escalonamento funciona em um escopo menor: que é gerenciar acesso a um recurso escasso buscando otimizar alguma métrica relativa ao seu contexto de uso, como por exemplo acesso de processos ao processador.

\section{Algoritmo proposto}

O escalonador proposto para implementação segue a ideia básica de escalonamento de listas. Haverão três listas: lista de tarefas a serem feitas, lista de \acrshort{CPU}s disponíveis e lista de \acrshort{GPU}s disponíveis.
A lista de tarefas é ordenada por tempo previsto de execução, que é dado por um estimativa a partir do programa a ser rodado e do arquivo de entrada. Essa ordenação será em ordem decrescente de tempo previsto. A lista de \acrshort{CPU}s disponíveis é ordenada com base na frequência e no número de núcleos. A lista de \acrshort{GPU}s tem sua ordem determinada pela quantidade de operações em pontos flutuante consegue realizar por segundo.

O escalonamento ocorre da seguinte forma, como ilustrado na figura \ref{Escalonamento} :\\
\newline
\iffalse
\begin{enumerate}
	\item Existem tarefas que podem ser executadas nos recursos disponíveis?
	\item Se sim, obtenha o processo que está no topo da lista.
	\begin{enumerate}
		\item É capaz de rodar em GPU?
		\item Se sim:
		\begin{enumerate}
			\item O tempo prevista para rodá-lo na melhor \acrshort{GPU} disponível é melhor que o tempo previsto para rodá-lo na melhor \acrshort{CPU} disponível?
			\item Se sim, escalone-o para nessa \acrshort{GPU}.
			\item Se não, escalone-o para na melhor \acrshort{CPU} disponível.
		\end{enumerate}
		\item Se não, escalone-o na melhor \acrshort{CPU} disponível.
		\item Remova a tarefa e o recurso alocado de suas respectivas listas.
	\end{enumerate}
	\item Se não, encerre o escalonamento.
	\item Volte para a regra 1.
\end{enumerate}
\fi
\begin{algorithm}
\caption{Escalonamento heterogêneo baseado em listas}
\begin{algorithmic}
	\Procedure{Escalonar}{listas lTarefas, lCPUs e lGPUs}
	\While{Existem tarefas que podem ser executadas nos recursos disponíveis?}
		\State{$aux \gets lTarefas[0] $}
		\If{aux é capaz de rodar em GPU}
			\If{$T_{previsto}(lGPUs[0]) < T_{previsto}(lCPUs[0])$}
			\State{Escalone\ aux\ para\ lGPUs[0]}
			\Else
				\State{Escalone\ aux\ para\ lCPUs[0]}
			\EndIf
		\Else
			\State{Escalone\ aux\ para\ lCPUs[0]}
		\EndIf
		\State{Remova a tarefa e o recurso alocado de suas respectivas listas.}
	\EndWhile
	\State{Encerra escalonamento}
\EndProcedure
\end{algorithmic}
\end{algorithm}


\begin{figure}[htbp]
%	\centerline{\includegraphics[scale=0.04]{img/EscalonadorProposto.png}}
	\centerline{\includegraphics[scale=0.032]{img/EscalonadorProposto2.png}}
	\caption{Diagrama de Funcionamento do Algoritmo de Escalonamento.}
	\label{Escalonamento}
\end{figure}


Observa-se que, para o algoritmo supracitado seja válido, pressupõe-se, que toda tarefa do algoritmo é capaz de rodar em \acrshort{CPU}. O pressuposto simplifica o primeiro passo do algoritmo, pois se a lista de \acrshort{CPU}s não estiver vazia, essa condição é automaticamente satisfeita. Futuramente pode ser necessário adaptá-lo para ser capaz de lidar com tarefas que só são capazes de serem executadas em \acrshort{GPU}.

O próximo capítulo apresentará o BioNimbuZ, a plataforma de federação de nuvem selecionada para a implementação de algoritmo, também serão apresentados informação sobre a implementação do escalonador.

COLOCAR EM TRANALHOS FUTUROS: Como trabalho futuro, se o BioNimbuZ obtiver suporte executação de uma mesma tarefa de forma distribuída, uma pequena modificação que pode ser feita no algoritmo supracitado é: ao invés de remover as tarefas escalonadas da lista de tarefas, colocá-las no fim dessa mesma lista. Fará com que o escalonamento seja interrompido apenas quando todos os recursos disponíveis forem alocados, pois sempre haverá tarefas para serem alocadas.

